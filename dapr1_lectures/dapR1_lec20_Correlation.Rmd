---
title: "<b>Correlation</b>"
subtitle: "<small>Data Analysis for Psychology in R 1<br>Semester 2 Week 10</small>"
author: "<b>Dr Emma Waterston</b>"
institute: "Department of Psychology<br/>The University of Edinburgh"
output:
  xaringan::moon_reader:
    self_contained: true
    css: 
      - un-xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)

options(htmltools.dir.version = FALSE)
#options(digits = 4, scipen = 2)
options(knitr.table.format = "html")

knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE, message = FALSE,
  cache = FALSE,
  dev = "png",
  fig.align = 'center',
  fig.height = 5, fig.width = 6,
  out.width = "80%",
  dpi = 300
)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro"),
  outfile = "un-xaringan-themer.css"
)
```


```{r preamble, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
library(kableExtra)
library(moderndive)
library(faux)

theme_set(
    theme_classic(base_size = 15) +
    theme(plot.title = element_text(hjust = 0.5))
)
```


# Course Overview

.pull-left[

```{r echo = FALSE, results='asis'}
block1_name = "Exploratory Data Analysis"
block1_lecs = c("Research design and data",
                "Describing categorical data",
                "Describing continuous data",
                "Describing relationships",
                "Functions")
block2_name = "Probability"
block2_lecs = c("Probability theory",
                "Probability rules",
                "Random variables (discrete)",
                "Random variables (continuous)",
                "Sampling")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")
course_table(block1_name,block2_name,block1_lecs,block2_lecs, week = 0)
```


]

.pull-right[


```{r echo = FALSE, results='asis'}
block3_name = "Foundations of inference"
block3_lecs = c("Confidence intervals",
                "Hypothesis testing (p-values)",
                "Hypothesis testing (critical values)",
                "Hypothesis testing and confidence intervals",
                "Errors, power, effect size, assumptions")
block4_name = "Common hypothesis tests"
block4_lecs = c("One sample t-test",
                "Independent samples t-test",
                "Paired samples t-test",
                "Chi-square tests",
                "Correlation")

source("https://raw.githubusercontent.com/uoepsy/junk/main/R/course_table.R")
course_table(block3_name,block4_name,block3_lecs,block4_lecs,week=10)
```

]

---
# Learning Objectives

- Understand the difference between variance, covariance, and correlation  
- Know how to calculate both covariance and correlation  
- Understand how to interpret the correlation coefficient  
- Know how perform and interpret the results of a significance test of your correlation  
- Understand which form of correlation is most appropriate to use with your data


---
class: inverse, center, middle

# Example

---

# Running Program

- Suppose a running coach wants to know whether there is an association between a participants' time spent enrolled in their running program (recorded in days) and the maximum distance they can run (receded in miles)  

- We are provided with information on the last 100 participants to enroll on the program


---
# Data


```{r, echo=F, message = F}
set.seed(526)
dat <- rnorm_multi(100, mu = c(90, 13), sd = c(30,  7), varnames = c('daysInProgram', 'maxDistance'), r = 0.2)

dat$daysInProgram[dat$daysInProgram<0] <- dat$daysInProgram[dat$daysInProgram<0]-min(dat$daysInProgram)
dat$maxDistance[dat$maxDistance<0] <- dat$maxDistance[dat$maxDistance<0]-min(dat$maxDistance)

```

```{r,echo=TRUE}
head(dat)
```


---
# Visualisation 

.pull-left[

```{r, echo=TRUE, eval=FALSE, message = FALSE}
ggplot(dat, aes(daysInProgram, maxDistance)) + 
  geom_point() + 
  geom_smooth(method = 'lm', se=FALSE) +
  labs(x='Days In Program', 
       y='Max Distance (miles)', 
       title = "Association between Running Distance \nand Program Membership Duration")
```

]

.pull-right[

```{r, echo=F, message = F, fig.width=7, fig.height=5}
ggplot(dat, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + geom_smooth(method = 'lm', se=F, color = "#0F4C81") +
  labs(x='Days In Program', y='Max Distance (miles)', title = "Association between Running Distance \nand Program Membership Duration") + 
  theme(axis.text = element_text(size=12), axis.title = element_text(size=14, face = 'bold'))
```

]

---

class: center, middle
# **Questions?**

---

class: inverse, center, middle
# Variance & Covariance

---

# Variance Recap

.pull-left[
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}$$

+ **Variance:** Deviance around the mean of a single variable
]

.pull-right[
```{r, echo = F, fig.height=3, fig.width=5}
sampleDat <- tibble(Names=c('Alfred', 'Bernard', 'Clarence', 'Dorothy', 'Edna', 'Flora', 'Geraldine'),
                    daysInProgram=c(121.57, 99.73, 114.63, 78.37, 136.41, 126.42, 108.94),
                    maxDistance=c(8.53, 10.57, 8.01, 14.63, 27.03, 22.22, 6.77))

p1 <- ggplot(sampleDat, aes(Names, daysInProgram)) + geom_point(size=2, colour = "#0F4C81") +
  labs(x='Participant Name', y = 'Days in Program') + 
  theme(axis.text = element_text(size=10), axis.title = element_text(size=12, face = 'bold')) +
  scale_y_continuous(breaks=seq(80, 140, by = 20), limits = c(70, 145))

p1
```

]

---
count: false

# Variance Recap

.pull-left[
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}$$

+ where:

   + $\sum_{i=1}^{n}$  the sum over all data values
   + $x_i$ = the $i$-th observation in the sample
   + $\bar{x}$ = the sample mean
   + $n$ = sample size

+ **Variance:** Deviance around the mean of a single variable

+ Raw deviation is the distance between each person's days in the program and the mean number of days in the program 
]

.pull-right[
```{r, echo = F, fig.height=3, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  labs(x='Participant Name', y = 'Days In Program') + 
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= "#0F4C81")
```
]

---
count: false

# Variance Recap

```{r, echo = F}
sampleDat$varX <- sampleDat$daysInProgram-mean(sampleDat$daysInProgram)
sampleDat$varY <- sampleDat$maxDistance-mean(sampleDat$maxDistance)
sampleDat$varXY <- sampleDat$varX*sampleDat$varY
row.names(sampleDat) <- NULL
```


.pull-left[
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}$$

+ **Variance:** Deviance around the mean of a single variable

+ Raw deviation is the distance between each person's days in the program and the mean number of days in the program 

+ To get the variance, we:
  1. Square the values to get rid of the negative
  2. Sum them up and divide by $n-1$ to get the average deviation of the group from its mean
]

.pull-right[
```{r, echo = F, fig.height=3, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= "#0F4C81")
```
]

---

# Variance


$$s^2_x ~~=~~ \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}~~=~~s^2_x = \frac{2192.57}{7-1}~~ = ~~ s^2_x = 365.43$$

+ where $\bar{x} = `r round(mean(sampleDat$daysInProgram), 2)`$   
  


.center[


|        $x_i$                              |        $x_i - \bar{x}$          |            $(x_i - \bar{x})^2$    |
|------------------------------------------:|--------------------------------:|----------------------------------:|
| `r round(sampleDat$daysInProgram[1], 2)`  | `r round(sampleDat$daysInProgram[1]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[1]^2 , 2)` |
| `r round(sampleDat$daysInProgram[2], 2)`  | `r round(sampleDat$daysInProgram[2]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[2]^2, 2)` |
| `r round(sampleDat$daysInProgram[3], 2)`  | `r round(sampleDat$daysInProgram[3]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[3]^2, 2)` |
| `r round(sampleDat$daysInProgram[4], 2)`  | `r round(sampleDat$daysInProgram[4]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[4]^2, 2)` |
| `r round(sampleDat$daysInProgram[5], 2)`  | `r round(sampleDat$daysInProgram[5]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[5]^2, 2)` |
| `r round(sampleDat$daysInProgram[6], 2)`  | `r round(sampleDat$daysInProgram[6]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[6]^2, 2)` |
| `r round(sampleDat$daysInProgram[7], 2)`  | `r round(sampleDat$daysInProgram[7]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[7]^2, 2)` |
|                                           |                                                                        |  **`r round(sum(sampleDat$varX^2), 2)`**|

]

---
# Covariance Recap

.pull-left[
+ **Covariance:** A value that represents how two variables change together

+ Does $y$ differ from its mean in a similar way to $x$?
]

.pull-right[

```{r, echo = F, fig.height=2.5, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= "#0F4C81")
```

```{r, echo = F, fig.height=2.5, fig.width=5}
p2 <- ggplot(sampleDat, aes(Names, maxDistance)) + geom_point(size=2, colour = '#BF1932') +
  labs(x='Participant Name', y ='Max Distance (miles)') +
  theme(axis.text = element_text(size=10), axis.title = element_text(size=12, face = 'bold')) + 
  geom_hline(yintercept = mean(sampleDat$maxDistance)) + 
  geom_segment(x = sampleDat$Names, y = sampleDat$maxDistance, 
               xend = sampleDat$Names, yend = mean(sampleDat$maxDistance), linetype = "dashed",
               colour= '#BF1932') +
  scale_y_continuous(breaks=seq(0, 30, 10), limits = c(0, 33))

p2
```

]


---
count: false

# Covariance Recap

.pull-left[
+ **Covariance:** A value that represents how two variables change together

+ Does $y$ differ from its mean in a similar way to $x$?

+ Mathematically similar to variance:


**Variance**
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i-\bar{x})^2}}{n-1} = \frac{\sum_{i=1}^{n}{(x_i-\bar{x})(x_i-\bar{x})}}{n-1}$$



**Covariance**

$$Cov_{xy} = \frac{\sum_{i=1}^{n}{\color{base_color}{(x_i-\bar{x})}\color{#BF1932}{(y_i-\bar{y})}}}{n-1}$$
]

.pull-right[
```{r, echo = F, fig.height=2.5, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= "#0F4C81")
```

```{r, echo = F, fig.height=2.5, fig.width=5}
p2
```
]

---

# Covariance Recap

.pull-left[
+ It's possible two variables are related if their observations differ proportionally from their means in a consistent way

+ Covariance gives us a sense of this...

  + High covariance suggests a stronger association than a lower covariance

  + Why can't we stop here? 
  
  + Why is correlation necessary? 

]


.pull-right[
```{r, echo = F, fig.height=2.5, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= "#0F4C81")
```

```{r, echo = F, fig.height=2.5, fig.width=5}
p2
```
]

---

# The Trouble with Covariance

.pull-left[


$$Cov_{xy}=\frac{\sum_{i=1}^n\color{#BF1932}{(x_i-\bar{x})}(y_i-\bar{y})}{n-1}$$
<br>

|        $x_i$                             |        $x_i - \bar{x}$         |
|-----------------------------------------:|--------------------------------:|
| `r round(sampleDat$daysInProgram[1], 2)` | `r round(sampleDat$varX[1], 2)` |
| `r round(sampleDat$daysInProgram[2], 2)` | `r round(sampleDat$varX[2], 2)` |
| `r round(sampleDat$daysInProgram[3], 2)` | `r round(sampleDat$varX[3], 2)` |
| `r round(sampleDat$daysInProgram[4], 2)` | `r round(sampleDat$varX[4], 2)` |
| `r round(sampleDat$daysInProgram[5], 2)` | `r round(sampleDat$varX[5], 2)` |
| `r round(sampleDat$daysInProgram[6], 2)` | `r round(sampleDat$varX[6], 2)` |
| `r round(sampleDat$daysInProgram[7], 2)` | `r round(sampleDat$varX[7], 2)` |

]



.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
devX <- round((sampleDat$daysInProgram - mean(sampleDat$daysInProgram)), 2)
p3 <- p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= "#0F4C81") +
  geom_text(aes(label = devX), nudge_y=c(5, -5, 5, -5, 5, 5, -5))

p3
```

]

---
count: false

# The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})\color{#BF1932}{(y_i-\bar{y})}}{n-1}$$
<br>

|        $x_i$                             | $x_i - \bar{x}$                 |            $y_i$                       |            $y_i - \bar{y}$      |
|-----------------------------------------:|--------------------------------:|---------------------------------------:|--------------------------------:|
| `r round(sampleDat$daysInProgram[1], 2)` | `r round(sampleDat$varX[1], 2)` | `r round(sampleDat$maxDistance[1], 2)` |`r round(sampleDat$varY[1], 2)` |
| `r round(sampleDat$daysInProgram[2], 2)` | `r round(sampleDat$varX[2], 2)` | `r round(sampleDat$maxDistance[2], 2)` |`r round(sampleDat$varY[2], 2)` |
| `r round(sampleDat$daysInProgram[3], 2)` | `r round(sampleDat$varX[3], 2)` | `r round(sampleDat$maxDistance[3], 2)` |`r round(sampleDat$varY[3], 2)` |
| `r round(sampleDat$daysInProgram[4], 2)` | `r round(sampleDat$varX[4], 2)` | `r round(sampleDat$maxDistance[4], 2)` |`r round(sampleDat$varY[4], 2)` |
| `r round(sampleDat$daysInProgram[5], 2)` | `r round(sampleDat$varX[5], 2)` | `r round(sampleDat$maxDistance[5], 2)` |`r round(sampleDat$varY[5], 2)` |
| `r round(sampleDat$daysInProgram[6], 2)` | `r round(sampleDat$varX[6], 2)` | `r round(sampleDat$maxDistance[6], 2)` |`r round(sampleDat$varY[6], 2)` |
| `r round(sampleDat$daysInProgram[7], 2)` | `r round(sampleDat$varX[7], 2)` | `r round(sampleDat$maxDistance[7], 2)` |`r round(sampleDat$varY[7], 2)` |

]



.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3 
```

```{r, echo = F, fig.width=5, fig.height=2.5}
devY <- round((sampleDat$maxDistance - mean(sampleDat$maxDistance)), 2)

p4 <- p2 + geom_text(aes(label = devY), nudge_y=c(-3, -3, -3, 3, 3, 3, -3))

p4
```

]

---
count: false

# The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n\color{#BF1932}{(x_i-\bar{x})(y_i-\bar{y})}}{n-1}$$
<br>


|        $x_i - \bar{x}$          |            $y_i - \bar{y}$      | $(x_i - \bar{x})(y_i - \bar{y})$   |
|--------------------------------:|---------------------------------------------------------------------:|
| `r round(sampleDat$varX[1], 2)` | `r round(sampleDat$varY[1], 2)` |  `r round(sampleDat$varXY[1], 2)`  |
| `r round(sampleDat$varX[2], 2)` | `r round(sampleDat$varY[2], 2)` |  `r round(sampleDat$varXY[2], 2)`  |
| `r round(sampleDat$varX[3], 2)` | `r round(sampleDat$varY[3], 2)` |  `r round(sampleDat$varXY[3], 2)`  |
| `r round(sampleDat$varX[4], 2)` | `r round(sampleDat$varY[4], 2)` |  `r round(sampleDat$varXY[4], 2)`  |
| `r round(sampleDat$varX[5], 2)` | `r round(sampleDat$varY[5], 2)` |  `r round(sampleDat$varXY[5], 2)`  |
| `r round(sampleDat$varX[6], 2)` | `r round(sampleDat$varY[6], 2)` |  `r round(sampleDat$varXY[6], 2)`  |
| `r round(sampleDat$varX[7], 2)` | `r round(sampleDat$varY[7], 2)` |  `r round(sampleDat$varXY[7], 2)`  |

]


.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3
```

```{r, echo = F, fig.width=5, fig.height=2.5}
p4
```

]

---
count: false

# The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\color{#BF1932}{\sum_{i=1}^n}(x_i-\bar{x})(y_i-\bar{y})}{n-1}$$

<br>


|        $x_i - \bar{x}$          |            $y_i - \bar{y}$      | $(x_i - \bar{x})(y_i - \bar{y})$   |
|--------------------------------:|---------------------------------------------------------------------:|
| `r round(sampleDat$varX[1], 2)` | `r round(sampleDat$varY[1], 2)` |  `r round(sampleDat$varXY[1], 2)`  |
| `r round(sampleDat$varX[2], 2)` | `r round(sampleDat$varY[2], 2)` |  `r round(sampleDat$varXY[2], 2)`  |
| `r round(sampleDat$varX[3], 2)` | `r round(sampleDat$varY[3], 2)` |  `r round(sampleDat$varXY[3], 2)`  |
| `r round(sampleDat$varX[4], 2)` | `r round(sampleDat$varY[4], 2)` |  `r round(sampleDat$varXY[4], 2)`  |
| `r round(sampleDat$varX[5], 2)` | `r round(sampleDat$varY[5], 2)` |  `r round(sampleDat$varXY[5], 2)`  |
| `r round(sampleDat$varX[6], 2)` | `r round(sampleDat$varY[6], 2)` |  `r round(sampleDat$varXY[6], 2)`  |
| `r round(sampleDat$varX[7], 2)` | `r round(sampleDat$varY[7], 2)` |  `r round(sampleDat$varXY[7], 2)`  |
|                                 |                                 |  **`r round(sum(sampleDat$varXY), 2)`**|

]

.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3
```

```{r, echo = F, fig.width=5, fig.height=2.5}
p4
```

]

---

# The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}=\frac{`r round(sum(sampleDat$varXY), 2)`}{7-1}=`r round(sum(sampleDat$varXY)/6, 2)`$$


<br>


|        $x_i - \bar{x}$          |            $y_i - \bar{y}$      | $(x_i - \bar{x})(y_i - \bar{y})$   |
|--------------------------------:|---------------------------------------------------------------------:|
| `r round(sampleDat$varX[1], 2)` | `r round(sampleDat$varY[1], 2)` |  `r round(sampleDat$varXY[1], 2)`  |
| `r round(sampleDat$varX[2], 2)` | `r round(sampleDat$varY[2], 2)` |  `r round(sampleDat$varXY[2], 2)`  |
| `r round(sampleDat$varX[3], 2)` | `r round(sampleDat$varY[3], 2)` |  `r round(sampleDat$varXY[3], 2)`  |
| `r round(sampleDat$varX[4], 2)` | `r round(sampleDat$varY[4], 2)` |  `r round(sampleDat$varXY[4], 2)`  |
| `r round(sampleDat$varX[5], 2)` | `r round(sampleDat$varY[5], 2)` |  `r round(sampleDat$varXY[5], 2)`  |
| `r round(sampleDat$varX[6], 2)` | `r round(sampleDat$varY[6], 2)` |  `r round(sampleDat$varXY[6], 2)`  |
| `r round(sampleDat$varX[7], 2)` | `r round(sampleDat$varY[7], 2)` |  `r round(sampleDat$varXY[7], 2)`  |
|                                 |                                 |  **`r round(sum(sampleDat$varXY), 2)`**|

]

.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3
```

```{r, echo = F, fig.width=5, fig.height=2.5}
p4
```

]


---

# The Trouble with Covariance

+ A value of `r round(sum(sampleDat$varXY)/6, 2)` seems high...I think. Is it?

  + Maybe? But maybe not 
  
  + Covariance is related specifically to the scales of the variables we are analysing 
  
  + Variables with larger scales will naturally have larger covariance values


---

# The Trouble with Covariance

+ Consider what would happen if we converted our distance data to kilometers instead of miles

```{r, echo=F}
sampleDat$maxDistancekm <- sampleDat$maxDistance*1.61
```


.pull-left[

.center[**Miles**]

```{r, echo = 5, fig.height=3.5, fig.width=5}
p4
```


]

.pull-right[

.center[**Kilometers**]

```{r, echo = F, fig.height=3.5, fig.width=5}
sampleDat$varYkm <- sampleDat$maxDistancekm-mean(sampleDat$maxDistancekm)
sampleDat$varXYkm <- sampleDat$varX*sampleDat$varYkm

ggplot(sampleDat, aes(Names, maxDistancekm)) + geom_point(size=2, colour = '#88B04B') +
  labs(x='Participant Name', y = 'Max Distance (km)') + 
  theme(axis.text = element_text(size=10), axis.title = element_text(size=12, face = 'bold')) +
  scale_y_continuous(breaks=seq(20, 50, by = 10), limits = c(0, 50)) + geom_hline(yintercept = mean(sampleDat$maxDistancekm)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$maxDistancekm, 
               xend = sampleDat$Names, yend = mean(sampleDat$maxDistancekm), linetype = "dashed",
               colour= '#88B04B') +
  geom_text(aes(label = devX), nudge_y=c(-3, -3, -3, 3, 3, 3, -3))
```



]

---

# The Trouble with Covariance

.pull-left[

.center[**Miles**]

$$Cov_{xy} = \frac{`r round(sum(sampleDat$varXY), 2)`}{7-1} = `r round(sum(sampleDat$varXY)/6, 2)`$$


|        $x_i - \bar{x}$          |            $y_i - \bar{y}$      | $(x_i - \bar{x})(y_i - \bar{y})$   |
|--------------------------------:|---------------------------------------------------------------------:|
| `r round(sampleDat$varX[1], 2)` | `r round(sampleDat$varY[1], 2)` |  `r round(sampleDat$varXY[1], 2)`  |
| `r round(sampleDat$varX[2], 2)` | `r round(sampleDat$varY[2], 2)` |  `r round(sampleDat$varXY[2], 2)`  |
| `r round(sampleDat$varX[3], 2)` | `r round(sampleDat$varY[3], 2)` |  `r round(sampleDat$varXY[3], 2)`  |
| `r round(sampleDat$varX[4], 2)` | `r round(sampleDat$varY[4], 2)` |  `r round(sampleDat$varXY[4], 2)`  |
| `r round(sampleDat$varX[5], 2)` | `r round(sampleDat$varY[5], 2)` |  `r round(sampleDat$varXY[5], 2)`  |
| `r round(sampleDat$varX[6], 2)` | `r round(sampleDat$varY[6], 2)` |  `r round(sampleDat$varXY[6], 2)`  |
| `r round(sampleDat$varX[7], 2)` | `r round(sampleDat$varY[7], 2)` |  `r round(sampleDat$varXY[7], 2)`  |
|                                 |                                |  **`r round(sum(sampleDat$varXY), 2)`**|

]

.pull-right[

.center[**Kilometers**]

```{r, echo = F}
sampleDat$varYkm <- sampleDat$maxDistancekm-mean(sampleDat$maxDistancekm)
sampleDat$varXYkm <- sampleDat$varX*sampleDat$varYkm
```

$$Cov_{xy} = \frac{`r round(sum(sampleDat$varXYkm), 2)`}{7-1} = `r round(sum(sampleDat$varXYkm)/6, 2)`$$



|        $x_i - \bar{x}$          |            $y_i - \bar{y}$      | $(x_i - \bar{x})(y_i - \bar{y})$   |
|--------------------------------:|---------------------------------------------------------------------:|
| `r round(sampleDat$varX[1], 2)` | `r round(sampleDat$varYkm[1], 2)` |  `r round(sampleDat$varXYkm[1], 2)`  |
| `r round(sampleDat$varX[2], 2)` | `r round(sampleDat$varYkm[2], 2)` |  `r round(sampleDat$varXYkm[2], 2)`  |
| `r round(sampleDat$varX[3], 2)` | `r round(sampleDat$varYkm[3], 2)` |  `r round(sampleDat$varXYkm[3], 2)`  |
| `r round(sampleDat$varX[4], 2)` | `r round(sampleDat$varYkm[4], 2)` |  `r round(sampleDat$varXYkm[4], 2)`  |
| `r round(sampleDat$varX[5], 2)` | `r round(sampleDat$varYkm[5], 2)` |  `r round(sampleDat$varXYkm[5], 2)`  |
| `r round(sampleDat$varX[6], 2)` | `r round(sampleDat$varYkm[6], 2)` |  `r round(sampleDat$varXYkm[6], 2)`  |
| `r round(sampleDat$varX[7], 2)` | `r round(sampleDat$varYkm[7], 2)` |  `r round(sampleDat$varXYkm[7], 2)`  |
|                                 |                                |  **`r round(sum(sampleDat$varXYkm), 2)`**|


]

---

class: center, middle
# **Questions?**

---

class: inverse, center, middle
# The Correlation Coefficient

---

# Correlation

+ Correlation allows you to compare continuous variables across different scales without the magnitude of the variables skewing your results

+ The correlation coefficient, $r$, is the standardised version of covariance:

.f4[

$$r=\frac{\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}}{\sqrt{\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}}\sqrt{\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{n-1}}}$$
]


---
count: false

# Correlation

+ Correlation allows you to compare continuous variables across different scales without the magnitude of the variables skewing your results

+ **Pearson's product moment correlation**, $r$, is the standardised version of covariance:

.f4[

$$r=\frac{\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}}{\sqrt{\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}}\sqrt{\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{n-1}}} = \frac{Cov_{xy}}{s_xs_y}$$
]

+ By dividing covariance by the product of the standard deviations of $x$ and $y$, we remove issues with scale differences in the original variables

+ Because of this, you can use $r$ to investigate the association(s) between continuous variables with completely different ranges 

---
# Correlation


.pull-left[

.center[**Miles**]

|        $x_i - \bar{x}$          |            $(x_i - \bar{x})^2$    |        $y_i - \bar{y}$          |            $(y_i - \bar{y})^2$    |
|--------------------------------:|----------------------------------:|
| `r round(sampleDat$daysInProgram[1]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[1]^2 , 2)` |`r round(sampleDat$maxDistance[1]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[1]^2 , 2)` |
| `r round(sampleDat$daysInProgram[2]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[2]^2, 2)` |`r round(sampleDat$maxDistance[2]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[2]^2 , 2)` |
| `r round(sampleDat$daysInProgram[3]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[3]^2, 2)` |`r round(sampleDat$maxDistance[3]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[3]^2 , 2)` |
| `r round(sampleDat$daysInProgram[4]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[4]^2, 2)` |`r round(sampleDat$maxDistance[4]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[4]^2 , 2)` |
| `r round(sampleDat$daysInProgram[5]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[5]^2, 2)` |`r round(sampleDat$maxDistance[5]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[5]^2 , 2)` |
| `r round(sampleDat$daysInProgram[6]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[6]^2, 2)` |`r round(sampleDat$maxDistance[6]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[6]^2 , 2)` |
| `r round(sampleDat$daysInProgram[7]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[7]^2, 2)` |`r round(sampleDat$maxDistance[7]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[7]^2 , 2)` |
|                                                                        |  **`r round(sum(sampleDat$varX^2), 2)`**|                                                              |  **`r round(sum(sampleDat$varY^2), 2)`**|
  

$${s_x}~=~\sqrt{\frac{`r round(sum(sampleDat$varX^2), 2)`}{7-1}}~=~ `r round(sd(sampleDat$daysInProgram), 2)`~~{s_y}~=~\sqrt{\frac{`r round(sum(sampleDat$varY^2), 2)`}{7-1}}~=~ `r round(sd(sampleDat$maxDistance), 2)` \quad $$

]

.pull-right[

.center.f3[**Kilometers**]

|        $x_i - \bar{x}$          |            $(x_i - \bar{x})^2$    |        $y_i - \bar{y}$          |            $(y_i - \bar{y})^2$    |
|--------------------------------:|----------------------------------:|
| `r round(sampleDat$daysInProgram[1]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[1]^2 , 2)` |`r round(sampleDat$maxDistancekm[1]-mean(sampleDat$maxDistancekm), 2)`| `r round(sampleDat$varYkm[1]^2, 2)`|
| `r round(sampleDat$daysInProgram[2]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[2]^2, 2)` |`r round(sampleDat$maxDistancekm[2]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[2]^2 , 2)` |
| `r round(sampleDat$daysInProgram[3]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[3]^2, 2)` |`r round(sampleDat$maxDistancekm[3]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[3]^2 , 2)` |
| `r round(sampleDat$daysInProgram[4]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[4]^2, 2)` |`r round(sampleDat$maxDistancekm[4]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[4]^2 , 2)` |
| `r round(sampleDat$daysInProgram[5]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[5]^2, 2)` |`r round(sampleDat$maxDistancekm[5]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[5]^2 , 2)` |
| `r round(sampleDat$daysInProgram[6]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[6]^2, 2)` |`r round(sampleDat$maxDistancekm[6]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[6]^2 , 2)` |
| `r round(sampleDat$daysInProgram[7]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[7]^2, 2)` |`r round(sampleDat$maxDistancekm[7]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[7]^2 , 2)` |
|                                                                        |  **`r round(sum(sampleDat$varX^2), 2)`**|                                                              |  **`r round(sum(sampleDat$varYkm^2), 2)`**|


$$\quad {s_x}~=~\sqrt{\frac{`r round(sum(sampleDat$varX^2), 2)`}{7-1}}~=~ `r round(sd(sampleDat$daysInProgram), 2)`~~{s_y}~=~\sqrt{\frac{`r round(sum(sampleDat$varYkm^2), 2)`}{7-1}}~=~ `r round(sd(sampleDat$maxDistancekm), 2)`$$

]

---
# Correlation


.pull-left[

.center[**Miles**]

|        $x_i - \bar{x}$          |            $(x_i - \bar{x})^2$    |        $y_i - \bar{y}$          |            $(y_i - \bar{y})^2$    |
|--------------------------------:|----------------------------------:|
| `r round(sampleDat$daysInProgram[1]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[1]^2 , 2)` |`r round(sampleDat$maxDistance[1]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[1]^2 , 2)` |
| `r round(sampleDat$daysInProgram[2]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[2]^2, 2)` |`r round(sampleDat$maxDistance[2]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[2]^2 , 2)` |
| `r round(sampleDat$daysInProgram[3]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[3]^2, 2)` |`r round(sampleDat$maxDistance[3]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[3]^2 , 2)` |
| `r round(sampleDat$daysInProgram[4]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[4]^2, 2)` |`r round(sampleDat$maxDistance[4]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[4]^2 , 2)` |
| `r round(sampleDat$daysInProgram[5]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[5]^2, 2)` |`r round(sampleDat$maxDistance[5]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[5]^2 , 2)` |
| `r round(sampleDat$daysInProgram[6]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[6]^2, 2)` |`r round(sampleDat$maxDistance[6]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[6]^2 , 2)` |
| `r round(sampleDat$daysInProgram[7]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[7]^2, 2)` |`r round(sampleDat$maxDistance[7]-mean(sampleDat$maxDistance), 2)` | `r round(sampleDat$varY[7]^2 , 2)` |
|                                                                        |  **`r round(sum(sampleDat$varX^2), 2)`**|                                                              |  **`r round(sum(sampleDat$varY^2), 2)`**|
  


$$r = \frac{Cov_{xy}}{s_xs_y} =~~\frac{`r round(sum(sampleDat$varXY)/6, 2)`}{`r round(sd(sampleDat$daysInProgram),2)`\cdot`r round(sd(sampleDat$maxDistance),2)`}=`r round((sum(sampleDat$varXY)/6)/(sd(sampleDat$daysInProgram)*sd(sampleDat$maxDistance)), 2)`\quad $$
]

.pull-right[

.center.f3[**Kilometers**]

|        $x_i - \bar{x}$          |            $(x_i - \bar{x})^2$    |        $y_i - \bar{y}$          |            $(y_i - \bar{y})^2$    |
|--------------------------------:|----------------------------------:|
| `r round(sampleDat$daysInProgram[1]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[1]^2 , 2)` |`r round(sampleDat$maxDistancekm[1]-mean(sampleDat$maxDistancekm), 2)`| `r round(sampleDat$varYkm[1]^2, 2)`|
| `r round(sampleDat$daysInProgram[2]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[2]^2, 2)` |`r round(sampleDat$maxDistancekm[2]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[2]^2 , 2)` |
| `r round(sampleDat$daysInProgram[3]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[3]^2, 2)` |`r round(sampleDat$maxDistancekm[3]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[3]^2 , 2)` |
| `r round(sampleDat$daysInProgram[4]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[4]^2, 2)` |`r round(sampleDat$maxDistancekm[4]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[4]^2 , 2)` |
| `r round(sampleDat$daysInProgram[5]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[5]^2, 2)` |`r round(sampleDat$maxDistancekm[5]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[5]^2 , 2)` |
| `r round(sampleDat$daysInProgram[6]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[6]^2, 2)` |`r round(sampleDat$maxDistancekm[6]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[6]^2 , 2)` |
| `r round(sampleDat$daysInProgram[7]-mean(sampleDat$daysInProgram), 2)` | `r round(sampleDat$varX[7]^2, 2)` |`r round(sampleDat$maxDistancekm[7]-mean(sampleDat$maxDistancekm), 2)` | `r round(sampleDat$varYkm[7]^2 , 2)` |
|                                                                        |  **`r round(sum(sampleDat$varX^2), 2)`**|                                                              |  **`r round(sum(sampleDat$varYkm^2), 2)`**|

$$\quad r = \frac{Cov_{xy}}{s_xs_y} ~~=~~\frac{`r round(sum(sampleDat$varXYkm)/6, 2)`}{`r round(sd(sampleDat$daysInProgram),2)`\cdot`r round(sd(sampleDat$maxDistancekm),2)`}=`r round((sum(sampleDat$varXYkm)/6)/(sd(sampleDat$daysInProgram)*sd(sampleDat$maxDistancekm)), 2)`$$

]

---

# Correlation

+ Correlations measure the degree of association between two variables

+ If one variable changes, does the other variable also change?

+ If so, do they rise and fall together, or does one rise as the other falls?


---
# Correlation **in R**

+ To run a simple correlation, you can use `cor()`

+ Let's compute the correlation between the number of days in the program and the max running distance for our entire sample of `r nrow(dat)`:

--

```{r, echo = TRUE}
cor(dat$daysInProgram, dat$maxDistance)
```

--

+ Now we have a correlation value. But what does it mean?

---
# Interpreting $r$

+ Values of $r$ fall between -1 and 1.

  + Values closer to 0 indicate a weaker association  
  
  + More extreme values indicate a stronger association  
  
+ Interpretation:

```{r, echo = F}
ESint <- tibble(Strength=c('Weak', 'Moderate', 'Strong'), Value = c('.1 < |r| < .3', '.3 < |r| < .5', '|r| > .5'))
kable(ESint, align = c('l', 'c'))
```

---
# Interpreting $r$

+ Values of $r$ fall between -1 and 1

  + Values closer to 0 indicate a weaker association
  
  + More extreme values indicate a stronger association

.center[
```{r, echo = F, message = F, fig.height=4, fig.width = 9}
set.seed(504)
strCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0.8)
strCor$maxDistance[strCor$maxDistance<=0] <- 5
strCor$daysInProgram[strCor$daysInProgram<=0] <- 2
strCor$corrStrength <- 'Strong'

set.seed(1022)
modCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0.45)
modCor$corrStrength <- 'Moderate'
modCor$maxDistance[modCor$maxDistance<=0] <- 5

set.seed(86)
lowCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0.15)
lowCor$corrStrength <- 'Weak'

set.seed(86)
noCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0)
noCor$corrStrength <- 'None'

corDat <- rbind(strCor, modCor, lowCor, noCor)

corDat$corrStrength <- factor(corDat$corrStrength, levels = c('None', 'Weak', 'Moderate', 'Strong'))

corPlot <- ggplot(corDat, aes(daysInProgram, maxDistance)) + 
  geom_point(alpha = 0.7, size = 1) + 
  geom_smooth(method = 'lm', se = F, colour = "#0F4C81") +
  labs(x = 'Days in Program', y = 'Max Distance (miles)')

ann_text <- data.frame(daysInProgram = rep(75, 4),maxDistance = rep(0, 4),
                       lab = c(paste('r =', round(cor.test(noCor$daysInProgram, noCor$maxDistance)$estimate, 2)),
                               paste('r =', round(cor.test(lowCor$daysInProgram, lowCor$maxDistance)$estimate, 2)),
                               paste('r =', round(cor.test(modCor$daysInProgram, modCor$maxDistance)$estimate, 2)),
                               paste('r =', round(cor.test(strCor$daysInProgram, strCor$maxDistance)$estimate, 2))),
                       corrStrength = c('None', 'Weak', 'Moderate', 'Strong'))

ann_text$corrStrength <- factor(ann_text$corrStrength, levels = c('None', 'Weak', 'Moderate', 'Strong'))

corPlot + facet_grid(.~corrStrength) +
  theme(strip.text = element_text(size = 10, face = 'bold')) +
  geom_text(data = ann_text, label = ann_text$lab, size = 4)

```
]

---
# Interpreting $r$

+ The sign of $r$ says nothing about the strength of the association, but its direction

  + Positive values indicate that the two variables rise together or fall together.
  
  + Negative values indicate that as one variable increases, the other decreases, and vice versa

.pull-left[
```{r, echo = F, fig.height=3.5, fig.width=5}
set.seed(806)
negCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = -0.5)
negCor$maxDistance[negCor$maxDistance<=0] <- 5

ggplot(negCor, aes(daysInProgram, maxDistance)) + geom_point() + geom_smooth(method = 'lm', se = F, colour = "#0F4C81") + 
  labs(x='Days in Program', y='Max Distance (miles)') +
  scale_y_continuous(breaks = seq(0, 30, 10), limits = c(0, 35)) +
  theme(axis.text = element_text(size = 10), axis.title = element_text(size = 12, face = 'bold')) + 
  annotate('text', label = paste('r =', round(cor.test(negCor$daysInProgram, negCor$maxDistance)$estimate, 2)),
           x=150, y = 30, size = 4)
```
]

.pull-right[
```{r, echo = F, fig.height=3.5, fig.width=5}
ggplot(modCor, aes(daysInProgram, maxDistance)) + geom_point() + geom_smooth(method = 'lm', se = F, colour = "#0F4C81") + 
  labs(x='Days in Program', y = 'Max Distance (miles)') +
  scale_y_continuous(breaks = seq(0, 30, 10), limits = c(0, 35)) +
  theme(axis.text = element_text(size = 10), axis.title = element_text(size = 12, face = 'bold')) + 
  annotate('text', label = paste('r =', round(cor.test(modCor$daysInProgram, modCor$maxDistance)$estimate, 2)), 
           x = 45, y = 30, size = 4)
```
]
  
---
# Interpreting $r$

+ In some cases, $r$ is considered a descriptive statistic

  + $r$ is actually a direct measure of effect size:
  
      + It provides information about the strength of the association between two variables
      
      + It is a standardized measure
  
---

class: center, middle
# **Questions?**

---

class: inverse, center, middle
# Hypothesis Testing with $r$

---

# Hypotheses

+ There may be times that a correlation is the test of interest, and we can formulate associated hypotheses tests

+ There is no association between two random variables, so the null hypothesis should reflect this:

  + $H_0: r=0$

  + $H_{1\ two-tailed}:r\not=0$
  
  + $H_{1\ one-tailed}:r>0\ \lor\ r<0$

---

# Significance Testing

Remember the key steps of hypothesis testing:

1. Compute a test statistic

2. Locate the test statistic on a distribution that reflects the probability of each test statistic value, given that H0 is true.

3. Determine whether the probability associated with your test statistic is lower than $\alpha$

---

# Calculation

**Compute a test statistic**

+ The sampling distribution for $r$ is approximately normal with a large $n$, and is $t$ distributed when $n$ is small.

  + Thus, significance is assessed using a $t$-distribution

--

+ The $t$-statistic for a correlation is calculated as:

$$t=r\sqrt{\frac{n-2}{1-r^2}}$$
+ In our example:

```{r, echo = F}
rStat <- round(cor.test(dat$daysInProgram, dat$maxDistance)$estimate, 2)
denom <-round(1-(rStat^2),2)
tStat <- as.numeric(round(rStat*(sqrt((nrow(dat)-2)/denom)),2))
pVal <- as.numeric(round(2*pt(rStat*(sqrt((nrow(dat)-2)/denom)), df = nrow(dat)-2, lower.tail=F), 3))
```

$$t\ =\quad r\sqrt{\frac{n-2}{1-r^2}} \quad = \quad \ `r rStat`\cdot \sqrt{\frac{`r nrow(dat)`-2}{1-`r rStat`^2}}\ \quad = \quad \ `r rStat`\cdot \sqrt{\frac{`r nrow(dat)-2`}{`r denom`}}\ \quad = \quad \ `r rStat`\cdot \sqrt{`r round((nrow(dat)-2)/denom, 2)`}\ \quad = \quad \ `r tStat`$$
---

# Is our Test Significant?

**Locate the test statistic on a distribution**

.pull-left[

+ We have all of the pieces we need: 
  + Our $t$-statistic = $2.34$
  + We use a $t$ distribution with $n-2$ degrees of freedom, so degrees of freedom = $100 - 2 = 98$
      + $n-2$: we had to calculate the means of *two* variables (e.g., in our example `daysInProgram` and `maxDistance`)
  + We will use two-tailed $\alpha$ = .05

+ Now all we need is to calculate the $p$-value in order to make our decision

]

.pull-right[
```{r, echo=F, fig.height=3.5, fig.width=5, message = F}
corTestPlot <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
  stat_function(fun = dt, args = list(df = nrow(dat)-2), colour = "#0F4C81", size = 1) +
  labs(x='t', y = 'Probability') + 
  annotate(geom = 'text', x = -2, y = 0.3, label = paste('df =',nrow(dat)-2), colour = "#0F4C81", size = 8) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = 'bold'))

testDat <- seq(tStat, 4, by = .1)
dTest <- dt(testDat, df = nrow(dat)-2)
testDat <- data.frame(vals=testDat, prob=dTest)

corTestPlot + geom_vline(xintercept=tStat, linetype = 'dashed', color = "#0F4C81") +
  geom_area(data = testDat, aes(x=vals,y=prob), fill = "#0F4C81") 
```
]

---

# Is our Test Significant?

**Determine whether the probability associated with your test statistic is lower than $\alpha$**

.pull-left[

+ What proportion of the plot falls in the shaded area? 

```{r, echo=TRUE}
tibble(
  Exactp = round(2*(1-pt(2.34, 98)),2)
)
```

+ The probability that we would have a $t$-statistic at least as extreme as `r tStat` if $H_0$ were true is only `r pVal`   
  + $`r pVal`<.05$, so we conclude our results are significant (i.e., since $p$ < $\alpha$)
]

.pull-right[
```{r, echo=F, fig.height=3.5, fig.width=5, message = F}
testDat <- seq(tStat, 4, by = .1)
dTest <- dt(testDat, df = nrow(dat)-2)
testDat <- data.frame(vals=testDat, prob=dTest)

corTestPlot + geom_vline(xintercept=tStat, linetype = 'dashed', color = "#0F4C81") +
  geom_area(data = testDat, aes(x=vals,y=prob), fill = "#0F4C81") 
```
]

---

# Correlation **in R**

+ Use `cor.test()`

```{r, echo = TRUE}
cor.test(dat$daysInProgram, dat$maxDistance,
         alternative = "two.sided")
```

*Note: There might be a small amount of rounding error when we compare to calculated in **R**.*

---

# Write Up

There was a weak positive correlation between maximum distance and the number of days in program $(r = .23, t(98) = 2.37, p = .020)$. These results suggested that a greater number of days in the program was positively associated with a higher maximum running distance. 

---

class: center, middle
# **Questions?**

---

class: inverse, center, middle
# Assumptions

---

# Assumptions of Pearson Correlation

1. Variables must be interval or ratio (continuous)   
  
2. Variables must be normally distributed  
  
3. There must be no extreme outliers in your data  
  
4. The association between the two variables must be linear  
  
5. Homoscedasticity (homogeneity of variance)   

---

# Assumptions of Pearson Correlation

&nbsp;1. Variables must be interval or ratio (continuous)


  + Knowledge of your data
  
  + No Likert scales!
	

---

# Assumptions of Pearson Correlation

&nbsp;2. Variables must be normally distributed


.pull-left[
.center[**Max Distance**]

```{r, echo = T}
shapiro.test(dat$maxDistance)
```

```{r, echo = F, fig.height=2, fig.width=5}
ggplot(dat, aes(maxDistance)) + geom_histogram(aes(y=..density..), bins = 18, fill = "#0F4C81", colour = 'darkgray') +
  geom_density() + labs(x='Max Distance', y = 'Density') +
  stat_function(fun = dnorm, args = list(mean = mean(dat$maxDistance), sd = sd(dat$maxDistance)), colour = '#BF1932')
```
]

.pull-right[
.center[**Days in Program**]

```{r, echo = T}
shapiro.test(dat$daysInProgram)
```

```{r, echo = F, fig.height=2, fig.width=5}
ggplot(dat, aes(daysInProgram)) + geom_histogram(aes(y=..density..), bins = 18, fill = "#0F4C81", colour = 'darkgray') +
  geom_density() + labs(x='Days in Program', y = 'Density') +
  stat_function(fun = dnorm, args = list(mean = mean(dat$daysInProgram), sd = sd(dat$daysInProgram)), colour = '#BF1932')
```
]


---

# Assumptions of Pearson Correlation

&nbsp;3. There must be no extreme outliers in your data


.pull-left[

.center[**Ok!**]
```{r, echo = F, fig.height = 2.25, fig.width=5}
datPlot <- ggplot(dat, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + 
  geom_smooth(method = 'lm', se = F, colour = "#0F4C81") +
  labs(x='Days in Program', y = 'Max Distance (miles)') +
  scale_x_continuous(breaks=seq(0, 160, 40), limits=c(0, 165)) +
  scale_y_continuous(breaks=seq(0, 30, 10), limits = c(0, 35))

datPlot
```
]

.pull-right[
.center[**Should be investigated**]
```{r, echo = F, fig.height = 2.25, fig.width=5}
dat2 <- dat
dat2[nrow(dat2)+1, ] <- c(100, 49)
dat2[nrow(dat2)+1, ] <- c(250, 18)

ggplot(dat2, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + geom_smooth(method = 'lm', se = F, colour = "#0F4C81") +
  labs(x='Days in Program', y = 'Max Distance (miles)') +
  scale_x_continuous(limits=c(0, 250)) +
  scale_y_continuous(breaks=seq(0, 50, 10)) +
  annotate('point', x=100, y=49, colour="#BF1932") +
  annotate('point', x=250, y=18, colour="#BF1932")
```
]

---

# Assumptions of Pearson Correlation

&nbsp;4. The association between the two variables must be linear


.pull-left[
.center[**Ok!**]
```{r, echo = F, fig.height = 2.25, fig.width = 5, message=F}
datPlot
```

]

.pull-right[
.center[**Should be investigated**]
```{r, echo = F, fig.height = 2.25, fig.width = 5, message = F}
nonLinDat <- read.csv('https://uoepsy.github.io/data/anx_perf.csv')
nonLinDat <- nonLinDat[nonLinDat$anxiety<30,]
ggplot(nonLinDat, aes(anxiety, performance)) + geom_point() + geom_smooth(se=F, colour = "#0F4C81")
```
]

---

# Assumptions of Pearson Correlation

&nbsp;5. Homoscedasticity (homogeneity of variance)     


.pull-left[

.center[**Ok!**]
```{r, echo = F, fig.height = 2.25, fig.width = 5, message=F}
datPlot
```

]

.pull-right[

.center[**Should be investigated**]
```{r, echo = F, fig.height = 2.25, fig.width = 5, message = F}
set.seed(113)
dat2 <- rbind(dat, rnorm_multi(n=150, mu=c(130, 18), sd = c(15, 20), varnames = c('daysInProgram', 'maxDistance')))

ggplot(dat2, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + geom_smooth(method = 'lm', se = F, colour = "#0F4C81") +
  labs(x='Days in Program', y = 'Max Distance (miles)')
```
]

---

class: center, middle
# **Questions?**


---

class: inverse, center, middle
# Other Types of Correlation

---

# Types of Correlation

| Variable 1  | Variable 2  | Correlation Type |
|-------------|-------------|------------------|
| Continuous  | Continuous  | Pearson          |
| Continuous  | Categorical | Polyserial       |
| Continuous  | Binary      | Biserial         |
| Categorical | Categorical | Polychoric       |
| Binary      | Binary      | Tetrachoric      |
| Rank        | Rank        | Spearman         |
| Nominal     | Nominal     | Chi-square       |


---
# Spearman's Correlation

+ Spearman's $\rho$ (or rank-order correlation) uses data on the rank-ordering of $x$, $y$ responses for each individual
  
+ Spearman's $\rho$ is a nonparametric version of Pearson's $r$, so it doesn't require the same constraints on your data

+ When would we choose to use the Spearman correlation?
	+ If our data are naturally ranked data (e.g. a survey where the task is to rank foods and drinks in terms of preference)
	+ Our data are ordinal (e.g., Likert scales)
	+ If the data are non-normal or skewed
	+ If the data shows evidence of non-linearity

---
# Spearman's Correlation

+ Spearman's is not testing for linear associations, it is testing for increasing monotonic association

--

  + What?

--

.pull-left.center[
**Linear**
```{r, echo = F, fig.height=3.5, fig.width=5}
mono <- tibble(
  A = c(1,2,3,4,5,6,7,8,9,10),
  B = c(1,2,3,4,5,6,7,8,9,10),
  C = c(1,4,5,6,8,9,10,13,15,16)
)

lp <- mono %>%
  ggplot(., aes(x=A, y=B)) +
  geom_point() + 
  geom_line()

mp <- mono %>%
  ggplot(., aes(x=A, y=C)) +
  geom_point() + 
  geom_line()

lp
```
<br>
A perfectly linear association between A & B

]

.pull-right.center[
**Increasing Monotonic**
```{r, echo = F, fig.height=3.5, fig.width=5}
mp
```
<br>
A perfectly increasing monotonic association between A & C
]

---
# Monotonic Association

+ **Perfect Monotonic Association:** The rank position of all observations on Variable A is the same as the rank position of all observations on Variable C

.pull-left[

```{r, echo = F}
tibble(
  A = c(1,2,3,4,5,6,7,8,9,10),
  B = c(1,2,3,4,5,6,7,8,9,10),
  C = c(1,4,5,6,8,9,10,13,15,16)
) %>%
  mutate(
    ID = paste("ID", 1:10, sep = ""),
    Rank_A = rank(A),
    Rank_C = rank(C)
  ) %>%
  dplyr::select(., ID, A, C, Rank_A, Rank_C) %>%
  kable() %>%
  kable_styling(full_width = F)

```

]

.pull-right[
```{r, echo = F, fig.height=3.5, fig.width=5}
mp
```

]

---

# Calculating Spearman's $\rho$

$$\rho=1-\frac{6\sum{d^2_i}}{n(n^2-1)}$$
+ $d_i=$ rank( $x_i$ ) $-$ rank( $y_i$ )

+ Steps:
  1. Rank each variable from largest to smallest 
  2. Calculate the difference in rank for each person on the two variables
  3. Square the difference
  4. Sum the squared values

---

# Calculating Spearman's $\rho$ by Hand

+ Imagine we want to know whether the participants' ratings (on a 1-10 scale) of the program are associated with how difficult they found the program (on a 1-10 scale):

.pull-left[

```{r, echo = F}
ratings <- tibble(Names=sampleDat$Names, ProgRating =c(7, 8, 4, 2, 5, 3, 1), Difficulty=c(10, 9, 8, 5, 7, 1, 4))
kable(ratings)
```
]

.pull-right[

| $x_i$  | $y_i$  | $x_i$ ranked | $y_i$ ranked | $d{i}$  |  $d{i}^2$ |
|--------|--------|--------------|--------------|---------|-----------|
| 7      | 10     | 6            | 7            | -1      | 1         |
| 8      | 9      | 7            | 6            | 1       | 1         |
| 4      | 8      | 4            | 5            | -1      | 1         |
| 2      | 5      | 2            | 3            | -1      | 1         |
| 5      | 7      | 5            | 4            | 1       | 1         |
| 3      | 1      | 3            | 1            | 2       | 4         |
| 1      | 4      | 1            | 2            | -1      | 1         |
|        |        |              |              |         | **10**    |

]

<br>

$$\rho \quad = \quad 1-\frac{6\sum{d^2_i}}{n(n^2-1)} \quad = \quad 1-\frac{6 \cdot 10}{7\cdot(7^2-1)} \quad = \quad 1-\frac{60}{7 \cdot (49-1)} \quad = \quad 1-\frac{60}{336}  \quad = \quad 1-0.18  \quad = \quad 0.82 $$

---

# Spearman's $\rho$ **in R** 

+ You can also use `cor()` and `cor.test()` to calculate Spearman's $\rho$ in `R`

```{r, echo = TRUE}
cor.test(ratings$ProgRating, ratings$Difficulty,
         method = "spearman", #<<
         alternative = "two.sided")
```

+ Necessary to use when you have ties in your ranks (i.e., your ranks are not unique)  


---
# Summary

+ Today we have covered:  
  + The differences between variance, covariance, and correlation
  + How to calculate both covariance and correlation
  + How to interpret both the correlation coefficient and the results of the associated significance test
  + Other methods for correlation and calculated Spearman's $\rho$

---
# This Week

<script src="https://cdn.jsdelivr.net/npm/iconify-icon@2.1.0/dist/iconify-icon.min.js"></script>

.pull-left[
<iconify-icon icon="clarity:tasks-solid" width="64" height="64"  style="color: #0F4C81"></iconify-icon>

## Tasks

- Attend both lectures

- Attend your lab and work on the assessed report with your group (due by 12 noon on Friday 28th of March 2025)

- Complete the weekly quiz
    + Opened Monday at 9am
    + Closes Sunday at 5pm

]

.pull-right[
<iconify-icon icon="raphael:help" width="64" height="64"  style="color: #0F4C81"></iconify-icon>

## Support

- **Office Hours**: for one-to-one support on course materials or assessments<br>(see LEARN > Course information > Course contacts)

- **Piazza**: help each other on this peer-to-peer discussion forum

- **Student Adviser**: for general support while you are at university<br>(find your student adviser on MyEd/Euclid)
]


